```{r global_setup,  warning=FALSE, cache=FALSE,echo=FALSE,error=FALSE,results='hide'}
source("../common/slide_setup.R")
```

```{r script_setup,results='hide',cache=FALSE}
## The basic files and libraries needed for most presentations
source("../common/utility_functions.R")
```


Quantitative Big Imaging  
========================================================
author: Kevin Mader
date: 6 March 2014
width: 1440
height: 900
css: ../common/template.css
transition: rotate

## Basic Segmentation and Discrete Binary Structures


Course Outline
========================================================
- 20th February - Introductory Lecture
- 27th February - Filtering and Image Enhancement (A. Kaestner)
- 6th March - **Basic Segmentation, Discrete Binary Structures**
- 13th March - Advanced Segmentation
- 20th March - Analyzing Single Objects
- 27th March -  Analyzing Complex Objects
- 3rd April -  Spatial Distribution
- 10th April -  Statistics and Reproducibility
- 17th April - Dynamic Experiments
- 8th May - Big Data
- 15th May - Guest Lecture - Applications in Material Science
- 22th May - Project Presentations

Lesson Outline
========================================================
- Motivation
- The old ways
- Thresholding
 - Other types of images
 - Selecting a good threshold
- Implementation
- Morphology
- Applications


Literature / Useful References
========================================================
- Jean Claude, Morphometry with R
 - [Online](http://link.springer.com/book/10.1007%2F978-0-387-77789-4) through ETHZ
 - [Buy it](http://www.amazon.com/Morphometrics-R-Use-Julien-Claude/dp/038777789X)
- John C. Russ, “The Image Processing Handbook”,(Boca Raton, CRC Press)
 - Available [online](http://dx.doi.org/10.1201/9780203881095) within domain ethz.ch (or proxy.ethz.ch / public VPN) 

Motivation:  Why do we do imaging experiments?
========================================================
#incremental: true

- To get an idea of what is going on
- To test a hypothesis
 - Does temperature affect bubble size?
 - Is this gene important for cell shape and thus mechanosensation in bone?
 - Does higher canal volume make bones weaker?
 - Does the granule shape affect battery life expectancy?

***
- What we are looking at
![Standard Cell, http://en.wikipedia.org/wiki/File:Average_prokaryote_cell-_en.svg](ext-figures/Average_prokaryote_cell.svg) 
- What we get from the imaging modality 
```{r, fig.cap="Single Cell",fig.height=3}
dkimg<-jpeg::readJPEG("ext-figures/Average_prokaryote_cell.jpg")
material.img<-1-(dkimg[,,1]+dkimg[,,2]+dkimg[,,3])/3
# assume the sample is constant 0.1m thick and color indicates alpha
gray.img<-1.0*exp(-material.img*0.1)
cellImage<-im.to.df(gray.img)
ggplot(cellImage,aes(x=y,y=-x,fill=val))+
  geom_tile()+guides(fill=F)+theme_bw(20)
```


To test a hypothesis
========================================================
- We perform an experiment bone to see how big the cells are inside the tissue
$$\downarrow$$ ![Bone Measurement](ext-figures/tomoimage.png) 

### 2560 x 2560 x 2160 x 32 bit = 56GB / sample
- Filtering and Preprocessing!  
$$\downarrow$$
- 20h of computer time later ...
- 56GB of less noisy data
- Way too much data, we need to reduce

What did we want in the first place
========================================================

### _Single number_:
* volume fraction,
* cell count,
* average cell stretch,
* cell volume variability

Why do we perform segmentation?
========================================================

- In model-based analysis every step we peform, simple or complicated is related to an underlying model of the system we are dealing with
- [_Occam's Razor_](http://en.wikipedia.org/wiki/Occams_Razor) is very important here : The simplest solution is usually the right one
 - Bayesian, neural networks optimized using genetic algorithms with Fuzzy logic has a much larger parameter space to explore, establish sensitivity in, and must perform much better and be tested much more thoroughly than thresholding to be justified

Review: Filtering and Image Enhancement
========================================================
incremental: true

- This was a noise process which was added to otherwise clean imaging data
- $$ I_{measured}(x,y) = I_{sample}(x,y) + \text{Noise}(x,y) $$
- What would the perfect filter be
 - $$ \textit{Filter} \ast I_{sample}(x,y) = I_{sample}(x,y) $$
 - $$ \textit{Filter} \ast \text{Noise}(x,y) = 0 $$ 
 - $$ \textit{Filter} \ast I_{measured}(x,y) = \textit{Filter} \ast I_{real}(x,y) + \textit{Filter}\ast \text{Noise}(x,y) \rightarrow \bf I_{sample}(x,y) $$
- What most filters end up doing
$$ \textit{Filter} \ast I_{measured}(x,y) = 90\%  I_{real}(x,y) + 10\% \text{Noise}(x,y) $$
- What bad filters do
$$ \textit{Filter} \ast I_{measured}(x,y) = 10\% I_{real}(x,y) + 90\% \text{Noise}(x,y) $$

What did people used to do?
========================================================

- What comes out of our detector / enhancement process 
```{r, fig.cap="Single Cell",fig.height=5}
ggplot(cellImage,aes(x=y,y=400-x,fill=val))+
  geom_tile()+guides(fill=F)+theme_bw(20)+labs(x="x",y="y")
```
***
- Identify objects by eye
 - Count, describe qualitatively: "many little cilia on surface", "long curly flaggelum", "elongated nuclear structure"
- Morphometrics
 - Trace the outline of the object (or sub-structures)
 - Can calculate the area by using equal-weight-paper and employing the "[cut-and-weigh](http://ion.chem.usu.edu/~sbialkow/Classes/361/GC/GC.html)" method


Quantitative Analysis
========================================================
- For segmentation this model is: 
 - there are 2 (or more) distinct components that make up the image
 - these components are distinguishable by their values (or vectors, colors, tensors, ...)
 - For absorption/attenuation microscopy, [Beer-Lambert Law](http://en.wikipedia.org/wiki/Attenuation_coefficient)
 $$ I_{detector} = I_{source}\exp(-\alpha d) $$
 - Different components have a different $\alpha$ based on the strength of the interaction between the light and the chemical / nuclear structure of the material
$$ I_{sample}(x,y) = I_{source}\exp(-\alpha(x,y) d) $$
$$ \alpha = f(N,Z,\sigma,\cdots) $$

***
```{r, fig.cap="Attenuation to Intensity",fig.height=4}
nx<-4
ny<-4
grad.im<-expand.grid(x=c(-nx:nx)/nx*2*pi,y=c(-ny:ny)/ny*2*pi)
phase.im<-runif(nrow(grad.im))
grad.im<-cbind(grad.im,
               col=1*(phase.im>0.66)+
                 2*(phase.im<0.33)+
                 0.4*runif(nrow(grad.im),min=-1,max=1))
bn.wid<-diff(range(grad.im$col))/10

bl.fun<-function(x) 1*exp(-x*0.5)

ggplot(grad.im,aes(x=col,y=bl.fun(col)))+
  geom_point(aes(color=cut_interval(col,3)))+
  geom_segment(data=data.frame(
    x=c(0.5,1.5),y=c(0.25),
    xend=c(0.5,1.5),yend=c(1.25)
    ),aes(x=x,y=y,xend=xend,yend=yend),fill="red",size=3,alpha=0.5)+
  labs(x=expression(alpha(x,y)),y=expression(paste("I"[sample],"(x,y)")),title="Probability Density Function",fill="Groups")+theme_bw(20)
```

```{r, fig.cap="Image Histogram",fig.height=5}
ggplot(grad.im,aes(x=col))+
  geom_density(aes(fill=cut_interval(col,3)))+
  geom_segment(data=data.frame(
    x=c(0.5,1.5),y=c(0),
    xend=c(0.5,1.5),yend=c(6)
    ),aes(x=x,y=y,xend=xend,yend=yend),fill="red",size=3,alpha=0.5)+
  labs(x=expression(alpha(x,y)),y="Frequency",title="Probability Density Function",fill="Groups")+theme_bw(20)
```


Where does segmentation get us?
========================================================
incremental: true

- We convert a decimal value (or something even more complicated like 3 values for RGB images, a spectrum for hyperspectral imaging, or a vector / tensor in a mechanical stress field)
- to a single, discrete value (usually true or false, but for images with phases it would be each phase, e.g. bone, air, cellular tissue)

- __2560 x 2560 x 2160 x 32 bit = 56GB / sample__
$$\downarrow$$
- 2560 x 2560 x 2160 x **1 bit** = 1.75GB / sample

Applying a threshold to an image
========================================================
Start out with a simple image of a cross with added noise
$$ I(x,y) = f(x,y) $$
```{r, fig.cap=""}
nx<-5
ny<-5
cross.im<-expand.grid(x=c(-nx:nx)/nx*2*pi,y=c(-ny:ny)/ny*2*pi)
cross.im<-cbind(cross.im,
               col=1.5*with(cross.im,abs(cos(x*y))/(abs(x*y)+(3*pi/nx)))+
                 0.5*runif(nrow(cross.im)))
bn.wid<-diff(range(cross.im$col))/10
ggplot(cross.im,aes(x=x,y=y,fill=col))+
  geom_tile()+
  scale_fill_gradient(low="black",high="white")+
  labs(fill="Intensity")+
  theme_bw(20)
```
***
The intensity can be described with a probability density function 
$$ P_f(x,y) $$
```{r, fig.cap="Probability density function"}
ggplot(cross.im,aes(x=col))+geom_histogram(binwidth=bn.wid)+
  labs(x="Intensity",title="Probability Density Function")+
  theme_bw(20)
```

Applying a threshold to an image
========================================================
By examining the image and probability distribution function, we can _deduce_ that the underyling model is a whitish phase that makes up the cross and the darkish background
```{r, fig.cap="With Threshold Overlay"}
thresh.val<-0.75
cross.im$val<-(cross.im$col>=thresh.val)
ggplot(cross.im,aes(x=x,y=y))+
  geom_tile(aes(fill=col))+
  geom_tile(data=subset(cross.im,val),fill="red",color="black",alpha=0.3)+
  geom_tile(data=subset(cross.im,!val),fill="blue",color="black",alpha=0.3)+
  scale_fill_gradient(low="black",high="white")+
  labs(fill="Intensity")+
  theme_bw(20)
```

***

Applying the threshold is a deceptively simple operation
$$ I(x,y) = 
\begin{cases}
1, & f(x,y)\geq0.5 \\
0, & f(x,y)<0.5
\end{cases}$$
```{r, fig.cap="With Threshold Overlay"}
ggplot(cbind(cross.im,in.thresh=cross.im$col>=thresh.val),aes(x=col))+
  geom_histogram(binwidth=bn.wid,aes(fill=in.thresh))+
  labs(x="Intensity",color="In Threshold")+scale_fill_manual(values=c("blue","red"))+
  theme_bw(20)
```
Various Thresholds
========================================================

```{r, fig.cap="Threshold Histograms",fig.height=7}
thresh.vals<-c(2:10)/10
grad.im.th<-ldply(thresh.vals,function(thresh.val) 
  cbind(cross.im,thresh=thresh.val,in.thresh=(cross.im$col>=thresh.val)))
ggplot(grad.im.th,aes(x=col))+
  geom_histogram(binwidth=bn.wid,aes(fill=in.thresh))+
  labs(x="Intensity",fill="Above Threshold")+facet_wrap(~thresh)+
  theme_bw(15)
```

***
```{r, fig.cap="Threshold Images",fig.height=7}
ggplot(grad.im.th,aes(x=x,y=y))+
  geom_tile(aes(fill=in.thresh),color="black",alpha=0.75)+
  labs(fill="Above Threshold")+facet_wrap(~thresh)+
  theme_bw(20)
```

Segmenting Cells
========================================================

```{r, fig.cap="Cell Colony",fig.height=4}
cellImage<-im.to.df(jpeg::readJPEG("ext-figures/Cell_Colony.jpg"))
ggplot(cellImage,aes(x=x,y=y,fill=val))+
  geom_tile()+
  labs(fill="Intensity")+coord_equal()+
  theme_bw(20)
```
```{r, echo=FALSE,fig.height=3}
ggplot(cellImage,aes(x=val))+geom_histogram()+
  labs(x="Intensity")+theme_bw(20)
```

***

- We can peform the same sort of analysis with this image of cells
- This time we can derive the model from the basic physics of the system
 - The field is illuminated by white light of nearly uniform brightness
 - Cells absorb light causing darker regions to appear in the image
 - _Lighter_ regions have no cells
 - __Darker__ regions have cells

Different Threshold Values
========================================================
```{r, fig.cap="Cell Colony",fig.height=7}
th.vals<-seq(0.4,0.85,length.out=3)
thlabel<-function(x,...) switch(x,"Too low","Good","Too high")
im.vals<-ldply(1:length(th.vals),function(th.val)
  cbind(cellImage,
        in.thresh=ifelse(cellImage$val<th.vals[th.val],"Cell","Background"),
        th.val=th.vals[th.val],
        th.label=thlabel(th.val)))
ggplot(im.vals,aes(x=x,y=y,fill=in.thresh))+
  geom_raster()+facet_grid(th.label~.)+
  labs(fill="Phase")+
  theme_bw(20)+coord_equal()
```
***
```{r, echo=FALSE,fig.height=7}
ggplot(im.vals,aes(x=val))+geom_histogram(aes(fill=in.thresh))+
  scale_y_sqrt()+
  theme_bw(20)+facet_grid(th.label~.)+labs(x="Intensity",y="Count",fill="Phase")
```

Other Image Types
========================================================
While scalar images are easiest, it is possible for any type of image
$$ I(x,y) = \vec{f}(x,y) $$
```{r, fig.cap=""}
nx<-7
ny<-7
n.pi<-4
grad.im<-expand.grid(x=c(-nx:nx)/nx*n.pi*pi,y=c(-ny:ny)/ny*n.pi*pi)

grad.im<-cbind(grad.im,
               col=1.5*with(grad.im,abs(cos(x*y))/(abs(x*y)+(3*pi/nx)))+
                 0.5*runif(nrow(grad.im)),
               x.vec=with(grad.im,y),
               y.vec=with(grad.im,x))
# normalize vector
grad.im[,c("x.vec","y.vec")]<-with(grad.im,cbind(x.vec/(sqrt(x.vec^2+y.vec^2)),
                                         y.vec/(sqrt(x.vec^2+y.vec^2))))
bn.wid<-c(diff(range(grad.im$x.vec))/10,diff(range(grad.im$y.vec))/10)
ggplot(grad.im,aes(x=x,y=y,fill=col))+
  geom_segment(aes(xend=x+x.vec,yend=y+y.vec),arrow=arrow(length = unit(0.15,"cm")),size=2)+
  scale_fill_gradient(low="black",high="white")+
  guides(fill=F)+labs(title="Orientation Map")+
  theme_bw(20)
```
***
The intensity can be described with two seperate or a single joint probability density function
$$ P_{\vec{f}\cdot \vec{i}}(x,y), P_{\vec{f}\cdot \vec{j}}(x,y) $$
```{r, fig.cap="With Threshold Overlay"}
ggplot(grad.im,aes(x=x.vec,y=y.vec))+
  stat_bin2d(binwidth=c(0.25,.25),drop=F)+
  labs(x="Pfx",y="Pfy",fill="Frequency",title="Orientation Histogram")+
  xlim(-1,1)+ylim(-1,1)+
  theme_bw(20)
```


Applying a threshold
========================================================
A threshold is now more difficult to apply since there are now two distinct variables to deal with. The standard approach can be applied to both
$$ I(x,y) = 
\begin{cases}
1, & \vec{f}_x(x,y) \geq0.25 \text{ and}\\
& \vec{f}_y(x,y) \geq0.25 \\
0, & \text{otherwise}
\end{cases}$$
```{r, fig.cap=""}
g.with.thresh<-cbind(grad.im,in.thresh=with(grad.im,x.vec>0.25 & y.vec>0.25))
ggplot(g.with.thresh,
       aes(x=x,y=y,fill=in.thresh,color=in.thresh))+
  geom_tile(alpha=0.5,aes(fill=in.thresh))+
  geom_segment(aes(xend=x+x.vec,yend=y+y.vec),arrow=arrow(length = unit(0.2,"cm")),size=3)+
  labs(color="In Threshold")+guides(fill=FALSE)+
  theme_bw(20)
```
***
This can also be shown on the joint probability distribution as 
```{r, fig.cap="With Threshold Overlay"}
bn.wid<-c(0.25,.25)
keep.bins<-expand.grid(x.vec=seq(-1,1,bn.wid[1]/10),y.vec=seq(-1,1,bn.wid[2]/10))
keep.bins<-cbind(keep.bins,in.thresh=with(keep.bins,x.vec>0.25 & y.vec>0.25))
ggplot(g.with.thresh,aes(x=x.vec,y=y.vec))+
  stat_bin2d(binwidth=bn.wid,drop=F)+
  geom_tile(data=subset(g.with.thresh,in.thresh),fill="red",alpha=0.4)+
  labs(x="Pfx",y="Pfy",fill="Threshold")+xlim(-1,1)+ylim(-1,1)+
  theme_bw(20)
```

Applying a threshold
========================================================
Given the presence of two variables; however, more advanced approaches can also be investigated. For example we can keep only components parallel to the x axis by using the dot product.
$$ I(x,y) = 
\begin{cases}
1, & |\vec{f}(x,y)\cdot \vec{i}| = 1 \\
0, & \text{otherwise}
\end{cases}$$
```{r ,fig.cap="",fig.width=7,fig.height=4}
i.vec<-c(1,0)
j.vec<-c(0,1)
g.cmp.thresh<-cbind(grad.im,in.thresh=with(grad.im,
                                            abs(x.vec*i.vec[1]+y.vec*i.vec[2])==1
                                            ))
ggplot(g.cmp.thresh,
       aes(x=x,y=y,fill=in.thresh,color=in.thresh))+
  geom_tile(alpha=0.5,aes(fill=in.thresh))+
  geom_segment(aes(xend=x+x.vec,yend=y+y.vec),arrow=arrow(length = unit(0.2,"cm")),size=3)+
  labs(color="In Threshold")+guides(fill=FALSE)+
  theme_bw(20)
```
Looking at Orientations
========================================================
We can tune the angular acceptance by using the fact $$\vec{x}\cdot\vec{y}=|\vec{x}| |\vec{y}| \cos(\theta_{x\rightarrow y}) $$
$$ I(x,y) = 
\begin{cases}
1, & \cos^{-1}(\vec{f}(x,y)\cdot \vec{i}) \leq \theta^{\circ} \\
0, & \text{otherwise}
\end{cases}$$
***
```{r, fig.cap="",results='hide'}
i.vec<-c(1,0)
j.vec<-c(0,1)
ang.accept<-function(c.ang) g.cmp.thresh<-cbind(grad.im,
                                                ang.val=c.ang,
                                                in.thresh=with(grad.im,
                                            acos(x.vec*i.vec[1]+y.vec*i.vec[2])<=c.ang/180*pi
                                            ))
ang.vals<-seq(5,180,length.out=9)
ggplot(ldply(ang.vals,ang.accept),
       aes(x=x,y=y,fill=in.thresh,color=in.thresh))+
  geom_tile(alpha=0.5,aes(fill=in.thresh))+
  geom_segment(aes(xend=x+x.vec,yend=y+y.vec),arrow=arrow(length = unit(0.2,"cm")),size=3)+
  facet_wrap(~ang.val)+
  labs(color="In Threshold")+guides(fill=FALSE)
  theme_bw(20)
```


Other Image Types
========================================================
Going beyond vector the possibilities for images are limitless. The following shows a tensor plot with the tensor represented as an ellipse. 
$$ I(x,y) = \hat{f}(x,y) $$
```{r, fig.cap="",fig.height=3}
nx<-4
ny<-4
n.pi<-4
grad.im<-expand.grid(x=c(-nx:nx)/nx*n.pi*pi,
                     y=c(-ny:ny)/ny*n.pi*pi)

grad.im<-cbind(grad.im,
               col=1.5*with(grad.im,abs(cos(x*y))/(abs(x*y)+(3*pi/nx)))+
                 0.5*runif(nrow(grad.im)),
              a=with(grad.im,sqrt(2/(abs(x)+0.5))),
               b=with(grad.im,0.5*sqrt(abs(x)+1)),
              th=0.5*runif(nrow(grad.im)),
              aiso=1,count=1)

create.ellipse.points<-function(x.off=0,y.off=0,a=1,b=NULL,th.off=0,th.max=2*pi,pts=36,...) {
  if (is.null(b)) b<-a
  th<-seq(0,th.max,length.out=pts)
  data.frame(x=a*cos(th.off)*cos(th)+b*sin(th.off)*sin(th)+x.off,
             y=-1*a*sin(th.off)*cos(th)+b*cos(th.off)*sin(th)+y.off,
             id=as.factor(paste(x.off,y.off,a,b,th.off,pts,sep=":")),...)
}
deform.ellipse.draw<-function(c.box) {
  create.ellipse.points(x.off=c.box$x[1],
                        y.off=c.box$y[1],
                        a=c.box$a[1],
                        b=c.box$b[1],
                        th.off=c.box$th[1],
                        col=c.box$col[1])                    
}

# normalize vector
tens.im<-ddply(grad.im,.(x,y),deform.ellipse.draw)

ggplot(tens.im,aes(x=x,y=y,group=as.factor(id),fill=col))+
  geom_polygon(color="black")+coord_fixed(ratio=1)+scale_fill_gradient(low="black",high="white")+guides(fill=F)+
  theme_bw(20)
```
Once the variable count is above 2, individual density functions and a series of cross plots are easier to interpret than some multidimensional density hypervolume.

***

```{r, fig.cap="Variable distributions",fig.height=4}

ggplot(grad.im)+
  geom_histogram(aes(x=a,fill="Width"),alpha=0.7)+
  geom_histogram(aes(x=b,fill="Height"),alpha=0.7)+
  geom_histogram(aes(x=th,fill="Orientation"),alpha=0.7)+
  geom_histogram(aes(x=col,fill="Color"),alpha=0.7)+
  guides(color=F)+labs(fill="Variable")+
  theme_bw(15)
```

```{r, fig.cap="With Threshold Overlay",fig.height=4}

plot(grad.im[,c("a","b","th","col")])
```

Multiple Phases: Segmenting Shale
========================================================
% Shale provided from Kanitpanyacharoen, W. (2012). Synchrotron X-ray Applications Toward an Understanding of Elastic Anisotropy.
- Here we have a shale sample measured with X-ray tomography with three different phases inside (clay, rock, and air).
- The model is that because the chemical composition and density of each phase is different they will absorb different amounts of x-rays and appear as different brightnesses in the image
```{r, fig.cap="Shale Sample"}
shaleImage<-im.to.df(jpeg::readJPEG("ext-figures/ShaleSample.jpg"))
ggplot(shaleImage,aes(x=x,y=y,fill=val))+
  geom_tile()+
  labs(fill="Absorption (au)")+theme_bw(20)
```

***

Ideally we would derive 3 values for the thresholds based on a model for the composition of each phase and how much it absorbs, but that is not always possible or practical.
- While there are 3 phases clearly visible in the image, the histogram is less telling (even after being re-scaled).
```{r, echo=FALSE}
ggplot(shaleImage,aes(x=val))+geom_histogram()+
  scale_y_sqrt()+
  labs(x="Absorption Intensity",y="Counts")+theme_bw(20)
```

Multiple Segmentations
========================================================
For this exercise we choose arbitrarily 3 ranges for the different phases and perform visual inspection
```{r, echo=FALSE}
void.max<-0.2
clay.max<-0.5
thresh.fun<-function(x.val) {
  if(x.val<void.max) "Void"
  else if (x.val>void.max & x.val<clay.max) "Clay"
  else "Rock"
}
shale.vals<-cbind(shaleImage,th.label=sapply(shaleImage$val,thresh.fun))
ggplot(shale.vals,aes(x=val))+geom_histogram(aes(fill=th.label))+
  scale_y_sqrt()+
  theme_bw(20)+labs(x="Intensity",y="Count")
```
***
The relation can explicitly be written out as
$$ I(x) = 
\begin{cases}
\text{Void}, & 0 \leq x \leq 0.2  \\
\text{Clay}, & 0.2 < x \leq 0.5 \\
\text{Rock}, & 0.5 < x
\end{cases}$$
```{r, fig.cap="Segmented Images",fig.height=4}
ggplot(shale.vals,aes(x=x,y=y,fill=th.label,alpha=1-val))+coord_fixed(ratio=1)+
  geom_raster()+guides(fill=F,alpha=F)+theme_bw(20)+facet_wrap(~th.label)
```

Implementation
========================================================
The implementations of basic thresholds and segmentations is very easy since it is a unary operation of a single image
$$ f(I(\vec{x})) $$
In mathematical terms this is called a map and since it does not require information from neighboring voxels or images it can be calculated for each point independently (_parallel_). Filters on the other hand almost always depend on neighboring voxels and thus the calculations are not as easy to seperate. 

Implementation Code 
========================================================
### Matlab
The simplist is a single threshold in Matlab: 
```
thresh_img = gray_img > thresh
```

A more complicated threshold: 
```
thresh_img = (gray_img > thresh_a) & (gray_img > thresh_b)
```

### Python (numpy)
``` 
thresh_img = gray_img > thresh
```

### Python
``` 
thresh_img = map(lambda gray_val: gray_val>thresh,
                gray_img)
```

***

### Java
```
boolean[] thresh_img = new boolean[x_size*y_size*z_size];
for(int x=x_min;x<x_max;x++)
  for(int y=y_min;y<y_max;y++)
    for(int z=z_min;z<z_max;z++) {
      int offset=(z*y_size+y)*x_size+x;
      thresh_img[offset]=gray_img[offset]>thresh;
    }
```
  
### In C/C++

```
bool* thresh_img = malloc(x_size*y_size*z_size * sizeof (bool));

for(int x=x_min;x<x_max;x++)
  for(int y=y_min;y<y_max;y++)
    for(int z=z_min;z<z_max;z++) {
      int offset=(z*y_size+y)*x_size+x;
      thresh_img[offset]=gray_img[offset]>thresh;
    }
```

Pitfalls with Segmentation
========================================================
type: alert
### Partial Volume Effect
- The [partial volume effect](http://bit.ly/1mW7kdP) is the name for the effect of discretization on the image into pixels or voxels.
- Surfaces are complicated, voxels are simple boxes which make poor representations
- Many voxels are only partially filled, but only the voxels on the surface
- Removing the first layer alleviates issue

```{r, fig.cap="Partial Volume Effect",fig.height=4}
make.circle<-function(nx,r,nscale=1,
                      circ.fun=function(x,y,r) ((x^2+y^2)<r^2)) {
  ny<-nx
  grad.im<-expand.grid(x=c(-nx:nx)/nscale,y=c(-ny:ny)/nscale)
  grad.im$val<-with(grad.im,circ.fun(x,y,r))
  grad.im$nx<-nx
  grad.im$r<-r
  grad.im
}
#' Simulates partial volume effect by binning a data-frame
#'
#' 
#'
#' @param count is the number of bins to create for the final image
#' ...
part.vol.circ<-function(in.im,bin.count=2) {
  ddply.cutcols(in.im,.(cut_interval(x,bin.count),cut_interval(y,bin.count)),
                function(c.df) data.frame(val=mean(c.df$val),
                                          r=c.df$r[1],
                                          nx=c.df$nx[1]),
                cols=2)
}
r.list<-seq(2,9.5,length.out=9)
sph.list<-ldply(r.list,function(r) part.vol.circ(make.circle(100,r,10),20))
ggplot(sph.list,aes(x=x,y=y,fill=val))+
  geom_raster()+facet_wrap(~r)+
  theme_bw(20)+guides(fill=F)
```

***

```{r, fig.cap="Partial Volume Effect",fig.height=3}
ggplot(sph.list,aes(x=val,color=as.factor(r)))+
  geom_density(trim=T,adjust=1,kernel="biweight")+#facet_wrap(~r)+#scale_y_log10()+
  theme_bw(20)+labs(x="Intensity",y="Frequency",color="Radius")
```

- Shown as a function of radius

```{r,results="asis"}
pve.table<-ddply(sph.list,.(r),function(c.rad.df) data.frame(m.int=mean(c.rad.df$val),
                                                             m.sd=sd(c.rad.df$val)
                                                             )
                 )
names(pve.table)<-c("Radius","Mean Intensity","Sd Intensity")
kable(pve.table)
```
Morphology
========================================================
Returning to the original image of a cross
```{r, fig.cap="Cross With Threshold Overlay"}
nx<-8
ny<-8
cross.im<-expand.grid(x=c(-nx:nx)/nx*2*pi,y=c(-ny:ny)/ny*2*pi)
cross.im<-cbind(cross.im,
               col=with(cross.im,1.5*((abs(x)<2) | (abs(y)<2))+
                 0.5*runif(nrow(cross.im))))
thresh.val<-0.75
cross.im$val<-(cross.im$col>=thresh.val)
ggplot(cross.im,aes(x=x,y=y))+
  geom_tile(aes(fill=col))+
  geom_tile(data=subset(cross.im,val),fill="red",color="black",alpha=0.3)+
  geom_tile(data=subset(cross.im,!val),fill="blue",color="black",alpha=0.3)+
  scale_fill_gradient(low="black",high="white")+
  labs(fill="Intensity")+
  theme_bw(20)
```
We can now utilize information from neighborhood voxels to improve the results. These steps are called morphological operations.
***
Like filtering the assumption behind morphological operations are
- nearby voxels in __real__ images are related / strongly correlated with one another 
- noise and imaging artifacts are less spatially correlated. 

Therefore these imaging problems can be alleviated by adjusting the balance between local and neighborhood values.


Fundamentals: Neighborhood
========================================================
A neighborhood consists of the pixels or voxels which are of sufficient proximity to a given point. There are a number of possible definitions which largely affect the result when it is invoked.   
- A large neighborhood performs operations over larger areas / volumes
 - Computationally intensive
 - Can _smooth_ out features
- A small neighborhood performs operations over small areas / volumes
 - Computationally cheaper
 - Struggles with large noise / filling large holes
 
***

The neighborhood is important for a large number of image and other (communication, mapping, networking) processing operations:
- filtering
- morphological operations
- component labeling
- distance maps
- image correlation based tracking methods

Fundamentals: Neighbors in 2D
========================================================
For standard image operations there are two definitions of neighborhood. The 4 and 8 adjacent neighbors shown below. Given the blue pixel in the center the red are the 4-adjacent and the red and green make up the 8 adjacent. 
```{r, fig.cap=""}
morph.2d<-expand.grid(x=c(-1,0,1),y=c(-1,0,1))
morph.2d$r<-with(morph.2d,sqrt(x^2+y^2))

ggplot(morph.2d,aes(x=x,y=y))+
  geom_tile(color="black",
            aes(fill=ifelse(r==0,"Pixel of Interest",
                                   ifelse(r==1,"4-Adjacent","8-Adjacent")))
            )+
  geom_text(aes(label=3*(y+1)+x+1))+
  labs(fill="Pixel Type")+
  theme_bw(20)
```

Formal Neighborhood Definitions
========================================================
Formally these have two effectively equivalent, but different definitions. 
- Pixels which share a face (red line) with the pixel
- Pixels which share a vertex (yellow dot) with the pixel

```{r, fig.cap="",fig.height=3}

cent.pix<-data.frame(x=c(-1, 1,1,-1,-1)/2,
                     y=c(-1,-1,1, 1,-1)/2)
ggplot(morph.2d,aes(x=x,y=y))+
  geom_tile(color="black",size=1,alpha=0.7,
            aes(fill=ifelse(r==0,"Pixel of Interest",
                                   ifelse(r==1,"4-Adjacent","8-Adjacent")))
            )+
  geom_path(data=cent.pix,color="red",size=3)+
  geom_point(data=cent.pix,color="yellow",size=5)+
  geom_text(aes(label=3*(y+1)+x+1))+
  labs(fill="Pixel Type")+
  theme_bw(20)
```
***
- Pixels which are distance 1 from the pixel
- Pixels which are distance $\sqrt{2}$ from the pixel
```{r, fig.cap="",fig.height=3}
morph.2d<-expand.grid(x=c(-1,0,1),y=c(-1,0,1))
morph.2d$r<-with(morph.2d,sqrt(x^2+y^2))
ggplot(morph.2d,aes(x=x,y=y))+
  geom_tile(color="black",
            aes(fill=ifelse(r==0,"Pixel of Interest",
                                   ifelse(r==1,"4-Adjacent","8-Adjacent")))
            )+
  geom_text(aes(label=round(r*100)/100))+
  labs(fill="Pixel Type")+
  theme_bw(20)
```

Formal Neighborhood Definitions in 3D
========================================================
In 3D there is now an additional group to consider because of the extra-dimension
- Voxels which share a face (red line) with the voxel (6-adjacent)
- Voxels which share an edge (yellow dot) with the voxel (18-adjacent)
- Voxels which share a vertex (purple dot) with the voxel (26-adjacent)

```{r, fig.cap="",fig.height=3}
morph.3d<-expand.grid(x=c(-1,0,1),y=c(-1,0,1),z=c(-1,0,1))
morph.3d$r<-with(morph.3d,sqrt(x^2+y^2+z^2))

cent.pix.3d<-data.frame(x=c(-1, 1,1,-1,-1,-1, 1,1,-1,-1)/2,
                     y=c(-1,-1,1, 1,-1,-1,-1,1, 1,-1)/2,
                     z=c(-1,-1,-1,-1,-1,1, 1,1, 1, 1))
face.pix.3d<-data.frame(x=c(-1, 1, 1,-1,-1)/2,
                        y=c(-1,-1, 1, 1,-1)/2,
                        z=c( 0, 0, 0, 0, 0))
pixel.label<-function(r) ifelse(r==0,"Pixel of Interest",
                                   ifelse(r==1," 6-Adjacent",
                                          ifelse(r==sqrt(2),"18-Adjacent","26-Adjacent")))
ggplot(morph.3d,aes(x=x,y=y))+
  geom_tile(color="black",size=1,alpha=0.7,
            aes(fill=pixel.label(r))
            )+
  geom_path(data=cent.pix.3d,color="yellow",size=3)+
  geom_point(data=cent.pix.3d,color="purple",size=5)+
  geom_path(data=face.pix.3d,color="red",size=3)+
  geom_point(data=face.pix.3d,color="yellow",size=5)+
  geom_text(aes(label=9*(z+1)+3*(y+1)+x+1))+
  facet_grid(~z)+
  labs(fill="Pixel Type")+
  theme_bw(20)
```
***
- Voxels which are distance 1 from the voxel
- Voxels which are distance $\sqrt{2}$ from the voxel
- Voxels which are distance $\sqrt{3}$ from the voxel
```{r, fig.cap="",fig.height=3}
ggplot(morph.3d,aes(x=x,y=y))+
  geom_tile(color="black",size=1,
            aes(fill=pixel.label(r))
            )+
  geom_text(aes(label=round(r*100)/100))+
  facet_grid(~z)+
  labs(fill="Pixel Type")+
  theme_bw(14)
```

Erosion and Dilation
========================================================

### Erosion
If any of the voxels in the neighborhood are 0/false than the voxel will be set to 0

- Has the effect of peeling the surface layer off of an object

***

### Dilation

If any of the voxels in the neigbhorhood are 1/true then the voxel will be set to 1
- Has the effect of adding a layer onto an object (dunking an strawberry in chocolate, adding a coat of paint to a car)

Applied Erosion and Dilation
========================================================

### Dilation
Taking an image of the cross at a too-high threshold, we show how dilation can be used to recover some of the missing pixels
```{r, fig.cap="Dilation Example",fig.height=3}
cross.im$thresh<-cross.im$col>1.75

cross.mat<-df.to.im(cross.im,"thresh",inv=T)
cross.df<-im.to.df(cross.mat)
ggplot(cross.df,aes(x=x,y=y))+
  geom_tile(data=subset(cross.df,val==0),aes(fill="original"),color="black",alpha=0.7)+
  labs(fill="Type")+
  theme_bw(20)
```
```{r, fig.cap="Dilation Example",fig.height=3}
cross.dil.mat<-imgStdBinaryDilation(cross.mat)
cross.dil.df<-im.to.df(cross.dil.mat)

ggplot(cross.df,aes(x=x,y=y))+
  geom_tile(data=subset(cross.df,val==0),aes(fill="original"),color="black",alpha=0.7)+
  geom_tile(data=subset(cross.dil.df,val==0),aes(fill="post dilation"),color="black",alpha=0.3)+
  labs(fill="Type")+
  theme_bw(20)
```

***

### Erosion
Taking an image of the cross at a too-low threshold, we show how erosion can be used to remove some of the extra pixels
```{r, fig.cap="Erosion Example",fig.height=3}
cross.im$thresh<-cross.im$col>0.4
cross.mat<-df.to.im(cross.im,"thresh",inv=T)
cross.df<-im.to.df(cross.mat)
ggplot(cross.df,aes(x=x,y=y))+
  geom_tile(data=subset(cross.df,val==0),aes(fill="original"),color="black",alpha=0.7)+
  labs(fill="Type")+
  theme_bw(20)
```
```{r, fig.cap="Erosion Example",fig.height=3}

cross.ero.mat<-imgStdBinaryErosion(cross.mat)
cross.ero.df<-im.to.df(cross.ero.mat)
ggplot(cross.df,aes(x=x,y=y))+
  geom_tile(data=subset(cross.df,val==0),aes(fill="original"),color="black",alpha=0.7)+
  geom_tile(data=subset(cross.ero.df,val==0),aes(fill="post erosion"),color="black",alpha=0.3)+
  labs(fill="Type")+
  theme_bw(20)
```


Opening and Closing
========================================================


### Opening

An erosion followed by a dilation operation

- Peels a layer off and adds a layer on
- Very small objects and connections are deleted in the erosion and do not return the image is thus __open__ed
- A cube larger than several voxels will have the exact same volume after (conservative)

***

### Closing

A dilation followed by an erosion operation

- Adds a layer and then peels a layer off
- Objects that are very close are connected when the layer is added and they stay connected when the layer is removed thus the image is __close__d
- A cube larger than one voxel will have the exact same volume after (conservative)


Applied Opening and Closing
========================================================

### Opening
Taking an image of the cross at a too-low threshold, we show how opening can be used to remove some of the extra pixels
```{r, fig.cap="Erosion Example",fig.height=3}
cross.im$thresh<-cross.im$col>0.4
cross.mat<-df.to.im(cross.im,"thresh",inv=T)
cross.df<-im.to.df(cross.mat)
ggplot(cross.df,aes(x=x,y=y))+
  geom_tile(data=subset(cross.df,val==0),aes(fill="original"),color="black",alpha=0.7)+
  labs(fill="Type")+
  theme_bw(20)
```
```{r, fig.cap="Erosion Example",fig.height=3}

cross.ero.mat<-imgStdBinaryOpening(cross.mat)
cross.ero.df<-im.to.df(cross.ero.mat)
ggplot(cross.df,aes(x=x,y=y))+
  geom_tile(data=subset(cross.df,val==0),aes(fill="original"),color="black",alpha=0.7)+
  geom_tile(data=subset(cross.ero.df,val==0),aes(fill="post opening"),color="black",alpha=0.3)+
  labs(fill="Type")+
  theme_bw(20)
```

***

### Closing
Taking an image of the cross at a too-high threshold, we show how closing can be used to recover some of the missing pixels
```{r, fig.cap="Dilation Example",fig.height=3}
cross.im$thresh<-cross.im$col>1.75

cross.mat<-df.to.im(cross.im,"thresh",inv=T)
cross.df<-im.to.df(cross.mat)
ggplot(cross.df,aes(x=x,y=y))+
  geom_tile(data=subset(cross.df,val==0),aes(fill="original"),color="black",alpha=0.7)+
  labs(fill="Type")+
  theme_bw(20)
```
```{r, fig.cap="Dilation Example",fig.height=3}
cross.dil.mat<-imgStdBinaryClosing(cross.mat)
cross.dil.df<-im.to.df(cross.dil.mat)

ggplot(cross.df,aes(x=x,y=y))+
  geom_tile(data=subset(cross.df,val==0),aes(fill="original"),color="black",alpha=0.7)+
  geom_tile(data=subset(cross.dil.df,val==0),aes(fill="post closing"),color="black",alpha=0.3)+
  labs(fill="Type")+
  theme_bw(20)
```

Applying Morphological Tools
========================================================

- For many applications morphology appears to be the same as filter
- The key difference is the avalanche or non-linear nature of the results
 - A single off voxel can turn its entire neighborhood off (erosion)
 - A single on voxel can turn its entire neighborhood on (dilation)
- The effects of this are most pronounced when performed iteratively
- This is very useful for filling holes, connecting objects, creating masks

***

A segmented slice taken from a cortical bone sample. The dark is the calcified bone tissue and the white are holes in the image

![Bone Slice](ext-figures/bone.png)

Filling Holes / Creating Masks
========================================================

```{r, fig.cap="Cortical Segment closing",fig.height=7}
cortbone.im<-imagedata(t(png::readPNG("ext-figures/bone.png")),"grey")
cortbone.df<-im.to.df(cortbone.im)
#cortbone.df$val<-255*(cortbone.df$val>0.5)
cortbone.close.im<-imgStdBinaryClosing(cortbone.im)
ggplot(subset(cortbone.df,val<1),aes(x=x,y=518-y))+
  geom_raster(data=subset(im.to.df(cortbone.close.im),val<1),
              aes(fill="closing 3x3"),alpha=0.8)+
  geom_raster(aes(fill="before closing"),alpha=0.6)+
  labs(fill="Image",y="y",x="x",title="3x3 Closing")+
  coord_equal()+
  theme_bw(20)
```

***

```{r, fig.cap="Cortical Segment closing 7",fig.height=7}
cortbone.close.im<-imgStdBinaryClosing(cortbone.im,dim=7)
ggplot(subset(cortbone.df,val<1),aes(x=x,y=600-y))+
  geom_raster(data=subset(im.to.df(cortbone.close.im),val<1),
              aes(fill="closing 7x7"),alpha=0.8)+
  geom_raster(aes(fill="before closing"),alpha=0.6)+
  labs(fill="Image",y="y",x="x",title="7x7 Closing")+
  coord_equal()+
  theme_bw(20)
```

Filling Holes / Creating Masks
========================================================

Applying the closing with even larger windows will close everything but being to destroy the underlying structure of the mask

```{r, fig.cap="Cortical Segment closing 19",fig.height=7}
full.kernel<-makeBrush(45,"box")
cortbone.close.im<-closing(cortbone.im<1,full.kernel)
ggplot(subset(cortbone.df,val<1),aes(x=x,y=600-y))+
  geom_raster(data=subset(im.to.df(cortbone.close.im),val>0),
              aes(fill="closing 45x45"),alpha=0.8)+
  geom_raster(aes(fill="before closing"),alpha=0.6)+
  labs(fill="Image",y="x",x="y",title="45x45 Closing")+
  coord_equal()+
  theme_bw(20)
```

***

We can characterize this by examining the dependency of the closing size and the volume fraction (note scale)

```{r, fig.cap="Cortical Segment closing 19",fig.height=3}
get.vf<-function(img) (100*sum(img>0)/
               (nrow(cortbone.im)*ncol(cortbone.im)))
vf.of.closing<-function(dim.size) {
  data.frame(dim.size=dim.size,
             vf.full=get.vf(closing(cortbone.im<1,makeBrush(dim.size,"box" )))
             )
  }
pt.list<-c(seq(1,10),seq(11,40,2))
vf.df<-ldply(pt.list,vf.of.closing,.parallel=T)
ggplot(vf.df,aes(x=dim.size))+
  geom_line(aes(y=vf.full))+
  labs(fill="Image",y="Bone Volume Frac(%)",x="Closing Size",title="Closing Size vs Volume Fraction")+
  theme_bw(15)
```

- Be careful when using large area opening / closing operations (always check the images)
- Noise and defects in images can be amplified with these larger operations


Different Kernels
========================================================

Using a better kernel shape (circular, diamond shaped, etc) the artifacts from morphological operations can be reduced

```{r, fig.cap="Cortical Segment closing 19",fig.height=7}
disc.kernel<-makeBrush(45,"disc")
cortbone.close.im<-closing(cortbone.im<1,disc.kernel)
ggplot(subset(cortbone.df,val<1),aes(x=x,y=600-y))+
  geom_raster(data=subset(im.to.df(cortbone.close.im),val>0),
              aes(fill="closing 45x45"),alpha=0.8)+
  geom_raster(aes(fill="before closing"),alpha=0.6)+
  labs(fill="Image",y="x",x="y",title="45x45 Closing")+
  coord_equal()+
  theme_bw(20)
```

***

We can characterize this by examining the dependency of the closing size and the volume fraction (note scale)

```{r, fig.cap="Cortical Segment closing Graph",fig.height=6}
get.vf<-function(img) (100*sum(img>0)/
               (nrow(cortbone.im)*ncol(cortbone.im)))
vf.of.closing<-function(dim.size) {
  data.frame(dim.size=dim.size,
             vf.full=get.vf(closing(cortbone.im<1,makeBrush(dim.size,"box" ))),
             vf.disc=get.vf(closing(cortbone.im<1,makeBrush(dim.size,"disc"))),
             vf.diam=get.vf(closing(cortbone.im<1,makeBrush(dim.size,"diamond"))),
             vf.vline=get.vf(closing(cortbone.im<1,makeBrush(dim.size,"line",angle=0))),
             vf.hline=get.vf(closing(cortbone.im<1,makeBrush(dim.size,"line",angle=90)))
             )
  }
pt.list<-c(seq(1,9,2),seq(11,60,4))
vf.df<-ldply(pt.list,vf.of.closing,.parallel=T)
ggplot(vf.df,aes(x=dim.size))+
  geom_line(aes(y=vf.full,color="Full"))+
  geom_line(aes(y=vf.disc,color="Circular"))+
  geom_line(aes(y=vf.diam,color="Diamond-Shape"))+
  geom_line(aes(y=vf.vline,color="Vertical Line"))+
  geom_line(aes(y=vf.hline,color="Horizontal Line"))+
  labs(color="Kernel Used",y="Bone Volume Fraction (%)",x="Closing Size",title="Closing Size vs Volume Fraction")+
  theme_bw(20)
```
- Alternative techniques
 - [Convex Hull](http://en.wikipedia.org/wiki/Convex_hull) - assuming convex shapes
 - [Flood Filling](http://en.wikipedia.org/wiki/Flood_fill) - fill connected pixels like in Microsoft Paint


Segmenting Fossils
========================================================
## Taken from the BBC Documentary [First Life](http://www.bbc.co.uk/programmes/b00vw49d) by David Attenborough
<video controls>
  <source src="ext-figures/PaleontologyMovie.m4v" type="video/mp4">
Your browser does not support the video tag.
</video>

- Gut Data
 - Slice 182 you can make out the intenstine track
- Teeth Data
 - Explore the sample and apply a threshold to locate the teeth using the 3D viewer



Quantifying Alzheimers: Segment the Cortex
========================================================
#### Courtesy of Alberto Alfonso
- Understand the progress of Alzheimer's disease as it relates to plaque formation in different regions of the brain 
![Cortex Image](ext-figures/cortex.png)

***

- First identify different regions
 - Manually contoured
![Cortex Mask](ext-figures/cortex_mask.png)

Quantifying Alzheimers: Segment the Cortex
========================================================
- The cortex is barely visible to the human eye
- Tiny structures hint at where cortex is located
```{r, fig.cap="Brain with Threshold",fig.height=5}
alz.df<-im.to.df(t(png::readPNG("ext-figures/cortex.png")))
ggplot(alz.df,aes(x=x,y=518-y))+
  geom_raster(aes(fill=val))+
  labs(fill="Electron Density",y="y",x="x")+
  coord_equal()+
  theme_bw(20)
```

***

- A simple threshold is insufficient to finding the cortical structures
- Other filtering techniques are unlikely to magicially fix this problem
```{r, fig.cap="Brain with Threshold",fig.height=5}
ggplot(alz.df,aes(x=x,y=518-y))+
  geom_raster(aes(fill=cut_interval(val,4)))+
  labs(fill="Segmented Phases",y="y",x="x")+
  coord_equal()+
  theme_bw(20)
```


Surface Area / Perimeter
========================================================

We see that the dilation and erosion affects are strongly related to the surface area of an object: the more surface area the larger the affect of a single dilation or erosion step. 

```{r, fig.cap="Surface Area Estimation",fig.height=4}
make.circle<-function(nx,r,nscale=1) {
  ny<-nx
  grad.im<-expand.grid(x=c(-nx:nx)/nscale,y=c(-ny:ny)/nscale)
  grad.im$val<-with(grad.im,(x^2+y^2)<r^2)
  grad.im$nx<-nx
  grad.im$r<-r
  grad.im
}
r.list<-seq(0.5,5,length.out=9)
ggplot(ldply(r.list,function(r) make.circle(10,r)),aes(x=x,y=y,fill=val))+
  geom_raster()+scale_fill_grey()+facet_wrap(~r)+
  theme_bw(20)+guides(fill=F)
```

***

```{r, fig.cap="Attenuation to Intensity",fig.height=4}
calc.eros.cnt<-function(nx,r,nscale=1,im.fun=make.circle) {
  in.cir<-im.fun(nx,r,nscale=nscale)
  cir.im<-df.to.im(in.cir)
  data.frame(nx=nx,r=r,nscale=nscale,
             dvolume=sum(dilate(cir.im>0,makeBrush(3,"diamond"))>0),
             evolume=sum(erode(cir.im>0,makeBrush(3,"diamond"))>0),
             volume=sum(cir.im>0)
             )
}
max.rad<-20
r.list<-seq(0.2,max.rad,length.out=20)
r.table<-ldply(r.list,function(r) calc.eros.cnt(max.rad+1,r,1))
r.table$model.perimeter<-with(r.table,2*pi*r)
r.table$estimated.perimeter<-with(r.table,
                                  ((dvolume-volume)+(volume-evolume))/2)
ggplot(r.table,aes(x=r))+
  geom_line(aes(y=estimated.perimeter,color="Morphological Estimation"))+
  geom_line(aes(y=model.perimeter,color="Model Circumference"))+
  labs(x="Radius",y="Perimeter",color="Source")+
  theme_bw(20)
```